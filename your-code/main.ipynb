{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Explore the Scikit-Learn Datasets\n",
    "\n",
    "Before starting to work on our own datasets, let's first explore the datasets that are included in this Python library. These datasets have been cleaned and formatted for use in ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the diabetes dataset. Do this in the cell below by importing the datasets and then loading the dataset  to the `diabetes` variable using the `load_diabetes()` function ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this variable by looking at the different attributes (keys) of `diabetes`. Note that the `load_diabetes` function does not return dataframes. It returns you a Python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "diabetes1 = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990842, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06832974, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286377, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04687948,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452837, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00421986,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': '/Users/pablogtorres/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_data.csv.gz',\n",
       " 'target_filename': '/Users/pablogtorres/opt/anaconda3/lib/python3.8/site-packages/sklearn/datasets/data/diabetes_target.csv.gz'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to read the description of the dataset. \n",
    "\n",
    "Print the description in the cell below using the `DESCR` attribute of the `diabetes` variable. Read the data description carefully to fully understand what each column represents.\n",
    "\n",
    "*Hint: If your output is ill-formatted by displaying linebreaks as `\\n`, it means you are not using the `print` function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the data description, answer the following questions:\n",
    "\n",
    "1. How many attributes are there in the data? What do they mean?\n",
    "\n",
    "1. What is the relation between `diabetes['data']` and `diabetes['target']`?\n",
    "\n",
    "1. How many records are there in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-9eb06500f3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Enter your answer here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdiabetes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dtypes'"
     ]
    }
   ],
   "source": [
    "# Enter your answer here:\n",
    "diabetes['data'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now explore what are contained in the *data* portion as well as the *target* portion of `diabetes`. \n",
    "\n",
    "Scikit-learn typically takes in 2D numpy arrays as input (though pandas dataframes are also accepted). Inspect the shape of `data` and `target`. Confirm they are consistent with the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "x = diabetes['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990842, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06832974, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286377, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04687948,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452837, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00421986,  0.00306441]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Perform Supervised Learning on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data have already been split to predictor (*data*) and response (*target*) variables. Given this information, we'll apply what we have previously learned about linear regression and apply the algorithm to the diabetes dataset.\n",
    "\n",
    "#### Let's briefly revisit the linear regression formula:\n",
    "\n",
    "```\n",
    "y = β0 + β1X1 + β2X2 + ... + βnXn + ϵ\n",
    "```\n",
    "\n",
    "...where:\n",
    "\n",
    "- X1-Xn: data \n",
    "- β0: intercept \n",
    "- β1-βn: coefficients \n",
    "- ϵ: error (cannot explained by model)\n",
    "- y: target\n",
    "\n",
    "Also take a look at the `sklearn.linear_model.LinearRegression` [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "#### In the cell below, import the `linear_model` class from `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new instance of the linear regression model and assign the new instance to the variable `diabetes_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "diabetes_model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's split the training and test data.\n",
    "\n",
    "Define `diabetes_data_train`, `diabetes_target_train`, `diabetes_data_test`, and `diabetes_target_test`. Use the last 20 records for the test data and the rest for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "diabetes_data_train = pd.DataFrame(diabetes.data[0:-20])\n",
    "diabetes_data_test = pd.DataFrame(diabetes.data[-20:])\n",
    "diabetes_target_train = pd.DataFrame(diabetes.target[0:-20])\n",
    "diabetes_target_test = pd.DataFrame(diabetes.target[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.078165</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.077863</td>\n",
       "      <td>0.052858</td>\n",
       "      <td>0.078236</td>\n",
       "      <td>0.064447</td>\n",
       "      <td>0.026550</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.040672</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>0.028758</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>-0.072854</td>\n",
       "      <td>0.108111</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>-0.019442</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>-0.003819</td>\n",
       "      <td>-0.047082</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.024053</td>\n",
       "      <td>0.023775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.078165</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.040696</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>-0.100638</td>\n",
       "      <td>-0.112795</td>\n",
       "      <td>0.022869</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.020289</td>\n",
       "      <td>-0.050783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030811</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.034229</td>\n",
       "      <td>0.043677</td>\n",
       "      <td>0.057597</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>0.057557</td>\n",
       "      <td>0.035462</td>\n",
       "      <td>0.085907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.034575</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.073119</td>\n",
       "      <td>-0.062691</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.045421</td>\n",
       "      <td>0.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.088642</td>\n",
       "      <td>0.087287</td>\n",
       "      <td>0.035582</td>\n",
       "      <td>0.021546</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>0.131470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.041840</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.033151</td>\n",
       "      <td>-0.022885</td>\n",
       "      <td>0.046589</td>\n",
       "      <td>0.041587</td>\n",
       "      <td>0.056003</td>\n",
       "      <td>-0.024733</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.009147</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.056863</td>\n",
       "      <td>-0.050428</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.045345</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.009919</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.070769</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.030996</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.047034</td>\n",
       "      <td>0.033914</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>0.057597</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>-0.002903</td>\n",
       "      <td>0.023239</td>\n",
       "      <td>0.055684</td>\n",
       "      <td>0.106617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.027310</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.060097</td>\n",
       "      <td>-0.029771</td>\n",
       "      <td>0.046589</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>0.122273</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.051401</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016281</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.008101</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.030232</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.045421</td>\n",
       "      <td>0.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.012780</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>-0.040099</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>-0.017629</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.038459</td>\n",
       "      <td>-0.038357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.056370</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.074108</td>\n",
       "      <td>-0.050428</td>\n",
       "      <td>-0.024960</td>\n",
       "      <td>-0.047034</td>\n",
       "      <td>0.092820</td>\n",
       "      <td>-0.076395</td>\n",
       "      <td>-0.061177</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.059744</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.067642</td>\n",
       "      <td>0.049341</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.018118</td>\n",
       "      <td>0.044485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>0.017282</td>\n",
       "      <td>-0.037344</td>\n",
       "      <td>-0.013840</td>\n",
       "      <td>-0.024993</td>\n",
       "      <td>-0.011080</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>-0.028674</td>\n",
       "      <td>0.026560</td>\n",
       "      <td>0.044528</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.045472</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.073030</td>\n",
       "      <td>-0.081414</td>\n",
       "      <td>0.083740</td>\n",
       "      <td>0.027809</td>\n",
       "      <td>0.173816</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.004220</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -0.078165  0.050680  0.077863  0.052858  0.078236  0.064447  0.026550   \n",
       "1   0.009016  0.050680 -0.039618  0.028758  0.038334  0.073529 -0.072854   \n",
       "2   0.001751  0.050680  0.011039 -0.019442 -0.016704 -0.003819 -0.047082   \n",
       "3  -0.078165 -0.044642 -0.040696 -0.081414 -0.100638 -0.112795  0.022869   \n",
       "4   0.030811  0.050680 -0.034229  0.043677  0.057597  0.068831 -0.032356   \n",
       "5  -0.034575  0.050680  0.005650 -0.005671 -0.073119 -0.062691 -0.006584   \n",
       "6   0.048974  0.050680  0.088642  0.087287  0.035582  0.021546 -0.024993   \n",
       "7  -0.041840 -0.044642 -0.033151 -0.022885  0.046589  0.041587  0.056003   \n",
       "8  -0.009147 -0.044642 -0.056863 -0.050428  0.021822  0.045345 -0.028674   \n",
       "9   0.070769  0.050680 -0.030996  0.021872 -0.037344 -0.047034  0.033914   \n",
       "10  0.009016 -0.044642  0.055229 -0.005671  0.057597  0.044719 -0.002903   \n",
       "11 -0.027310 -0.044642 -0.060097 -0.029771  0.046589  0.019980  0.122273   \n",
       "12  0.016281 -0.044642  0.001339  0.008101  0.005311  0.010899  0.030232   \n",
       "13 -0.012780 -0.044642 -0.023451 -0.040099 -0.016704  0.004636 -0.017629   \n",
       "14 -0.056370 -0.044642 -0.074108 -0.050428 -0.024960 -0.047034  0.092820   \n",
       "15  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
       "16 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
       "17  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
       "18 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
       "19 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
       "\n",
       "           7         8         9  \n",
       "0  -0.002592  0.040672 -0.009362  \n",
       "1   0.108111  0.015567 -0.046641  \n",
       "2   0.034309  0.024053  0.023775  \n",
       "3  -0.076395 -0.020289 -0.050783  \n",
       "4   0.057557  0.035462  0.085907  \n",
       "5  -0.039493 -0.045421  0.032059  \n",
       "6   0.034309  0.066048  0.131470  \n",
       "7  -0.024733 -0.025952 -0.038357  \n",
       "8   0.034309 -0.009919 -0.017646  \n",
       "9  -0.039493 -0.014956 -0.001078  \n",
       "10  0.023239  0.055684  0.106617  \n",
       "11 -0.039493 -0.051401 -0.009362  \n",
       "12 -0.039493 -0.045421  0.032059  \n",
       "13 -0.002592 -0.038459 -0.038357  \n",
       "14 -0.076395 -0.061177 -0.046641  \n",
       "15 -0.002592  0.031193  0.007207  \n",
       "16  0.034309 -0.018118  0.044485  \n",
       "17 -0.011080 -0.046879  0.015491  \n",
       "18  0.026560  0.044528 -0.025930  \n",
       "19 -0.039493 -0.004220  0.003064  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the training data and target to `diabetes_model`. Print the *intercept* and *coefficients* of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "model = diabetes_model.fit(diabetes_data_train, diabetes_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.03499549e-01, -2.37639315e+02,  5.10530605e+02,\n",
       "         3.27736980e+02, -8.14131709e+02,  4.92814588e+02,\n",
       "         1.02848452e+02,  1.84606489e+02,  7.43519617e+02,\n",
       "         7.60951722e+01]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152.76430692])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the results\n",
    "\n",
    "From the outputs you should have seen:\n",
    "\n",
    "- The intercept is a float number.\n",
    "- The coefficients are an array containing 10 float numbers.\n",
    "\n",
    "This is the linear regression model fitted to your training dataset.\n",
    "\n",
    "#### Using your fitted linear regression model, predict the *y* of `diabetes_data_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "diabetes_y_pred = model.predict(diabetes_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[206.75928628],\n",
       "       [ 68.44064739],\n",
       "       [178.20406005],\n",
       "       [166.59039906],\n",
       "       [129.47338697],\n",
       "       [105.48206978],\n",
       "       [ 74.90024045],\n",
       "       [120.73067569],\n",
       "       [159.82011958],\n",
       "       [211.92833532],\n",
       "       [ 97.83664191],\n",
       "       [ 97.41005509],\n",
       "       [115.60592349],\n",
       "       [164.92279039],\n",
       "       [103.34070745],\n",
       "       [177.68217359],\n",
       "       [210.75217394],\n",
       "       [184.40013153],\n",
       "       [148.54098532],\n",
       "       [123.55941211],\n",
       "       [120.97403176],\n",
       "       [ 86.41241445],\n",
       "       [113.06547293],\n",
       "       [252.35802827],\n",
       "       [165.0256223 ],\n",
       "       [147.87909701],\n",
       "       [ 97.36674337],\n",
       "       [179.12350572],\n",
       "       [129.58494812],\n",
       "       [185.38814558],\n",
       "       [158.11930901],\n",
       "       [ 69.5502975 ],\n",
       "       [263.36897831],\n",
       "       [113.46175282],\n",
       "       [ 79.56563326],\n",
       "       [ 87.72481273],\n",
       "       [207.0421844 ],\n",
       "       [157.45915639],\n",
       "       [240.65662115],\n",
       "       [137.1490856 ],\n",
       "       [155.31655344],\n",
       "       [ 74.42879297],\n",
       "       [146.31653437],\n",
       "       [ 78.52705268],\n",
       "       [222.11926084],\n",
       "       [126.59820508],\n",
       "       [141.84166437],\n",
       "       [109.44753606],\n",
       "       [ 75.09372891],\n",
       "       [190.42332738],\n",
       "       [159.23790309],\n",
       "       [171.06440722],\n",
       "       [134.14185441],\n",
       "       [159.31230491],\n",
       "       [138.94279895],\n",
       "       [ 73.39607055],\n",
       "       [207.21538369],\n",
       "       [ 80.45498482],\n",
       "       [103.89405947],\n",
       "       [135.51866843],\n",
       "       [113.7604739 ],\n",
       "       [181.57058967],\n",
       "       [ 61.77249359],\n",
       "       [ 98.88189256],\n",
       "       [115.70757199],\n",
       "       [191.02738602],\n",
       "       [150.90888198],\n",
       "       [125.92583944],\n",
       "       [116.54669748],\n",
       "       [124.03378216],\n",
       "       [ 75.55191024],\n",
       "       [237.48306485],\n",
       "       [141.50540223],\n",
       "       [125.7874299 ],\n",
       "       [151.92660098],\n",
       "       [128.96147947],\n",
       "       [192.53543155],\n",
       "       [ 77.39022131],\n",
       "       [167.09776732],\n",
       "       [ 91.31020128],\n",
       "       [175.17028723],\n",
       "       [124.29323949],\n",
       "       [ 63.18411355],\n",
       "       [151.78757246],\n",
       "       [ 53.60712124],\n",
       "       [165.98566436],\n",
       "       [ 44.4723183 ],\n",
       "       [152.23324167],\n",
       "       [ 81.62386207],\n",
       "       [107.2816144 ],\n",
       "       [ 80.87409188],\n",
       "       [187.27371075],\n",
       "       [192.57750449],\n",
       "       [ 60.72408869],\n",
       "       [106.4031363 ],\n",
       "       [125.49538842],\n",
       "       [208.99379988],\n",
       "       [214.59988147],\n",
       "       [123.54770557],\n",
       "       [139.99635036],\n",
       "       [167.79824717],\n",
       "       [108.58475774],\n",
       "       [149.32986674],\n",
       "       [159.19431647],\n",
       "       [152.351259  ],\n",
       "       [117.92793459],\n",
       "       [ 73.04375498],\n",
       "       [157.21237354],\n",
       "       [231.29179423],\n",
       "       [146.69328359],\n",
       "       [ 40.80100306],\n",
       "       [121.73643613],\n",
       "       [152.55087233],\n",
       "       [209.59441904],\n",
       "       [289.90775253],\n",
       "       [189.05011996],\n",
       "       [215.28486372],\n",
       "       [237.32410411],\n",
       "       [166.37285996],\n",
       "       [151.907107  ],\n",
       "       [157.19405036],\n",
       "       [201.84503346],\n",
       "       [220.58435724],\n",
       "       [176.89381347],\n",
       "       [169.39959973],\n",
       "       [187.68448576],\n",
       "       [ 57.68850542],\n",
       "       [107.99405973],\n",
       "       [ 92.59936412],\n",
       "       [212.23870609],\n",
       "       [245.41651206],\n",
       "       [ 69.4816247 ],\n",
       "       [114.41367356],\n",
       "       [ 69.79914347],\n",
       "       [140.31442169],\n",
       "       [239.90556041],\n",
       "       [ 58.60883226],\n",
       "       [235.72019943],\n",
       "       [255.73947027],\n",
       "       [253.12249817],\n",
       "       [157.6279999 ],\n",
       "       [231.98033091],\n",
       "       [170.76553345],\n",
       "       [117.61035691],\n",
       "       [179.93772788],\n",
       "       [238.81068308],\n",
       "       [190.57795278],\n",
       "       [228.0108628 ],\n",
       "       [114.36333784],\n",
       "       [178.23235423],\n",
       "       [209.81775597],\n",
       "       [144.9795296 ],\n",
       "       [202.60129801],\n",
       "       [123.80860815],\n",
       "       [151.63805944],\n",
       "       [198.97398769],\n",
       "       [146.59152212],\n",
       "       [125.27392182],\n",
       "       [ 86.03270707],\n",
       "       [234.82457586],\n",
       "       [ 82.84016948],\n",
       "       [231.27600488],\n",
       "       [144.36323971],\n",
       "       [198.48406939],\n",
       "       [147.06334862],\n",
       "       [ 77.98456984],\n",
       "       [ 60.16531688],\n",
       "       [263.50063179],\n",
       "       [226.2378663 ],\n",
       "       [219.1627738 ],\n",
       "       [ 48.11897346],\n",
       "       [ 88.90700468],\n",
       "       [222.1094987 ],\n",
       "       [ 97.92075863],\n",
       "       [165.3163388 ],\n",
       "       [121.62630945],\n",
       "       [159.11162765],\n",
       "       [223.77647264],\n",
       "       [100.21365939],\n",
       "       [166.44520444],\n",
       "       [180.27822407],\n",
       "       [ 90.61060421],\n",
       "       [173.45311624],\n",
       "       [160.50438597],\n",
       "       [201.91417101],\n",
       "       [186.05703896],\n",
       "       [196.96259576],\n",
       "       [ 66.47814072],\n",
       "       [154.88396506],\n",
       "       [117.37775276],\n",
       "       [197.02504012],\n",
       "       [128.99212268],\n",
       "       [ 92.25472599],\n",
       "       [141.37351287],\n",
       "       [155.92188295],\n",
       "       [171.07777829],\n",
       "       [ 99.62668276],\n",
       "       [192.35843191],\n",
       "       [142.33601676],\n",
       "       [176.87579872],\n",
       "       [ 97.12218811],\n",
       "       [ 70.42117942],\n",
       "       [163.92951642],\n",
       "       [199.22311971],\n",
       "       [181.48660328],\n",
       "       [227.29930221],\n",
       "       [161.41002772],\n",
       "       [211.79446617],\n",
       "       [224.66341593],\n",
       "       [175.32963083],\n",
       "       [124.96333003],\n",
       "       [175.91591988],\n",
       "       [153.1156677 ],\n",
       "       [ 99.72373002],\n",
       "       [100.00195178],\n",
       "       [263.53536082],\n",
       "       [225.48647667],\n",
       "       [222.38262709],\n",
       "       [134.55939169],\n",
       "       [145.07798763],\n",
       "       [ 54.84517001],\n",
       "       [142.09205052],\n",
       "       [154.79870054],\n",
       "       [124.46470533],\n",
       "       [ 78.0745732 ],\n",
       "       [231.034711  ],\n",
       "       [ 78.67174011],\n",
       "       [106.97791537],\n",
       "       [117.81672   ],\n",
       "       [ 99.53040319],\n",
       "       [165.91262249],\n",
       "       [160.30651046],\n",
       "       [159.59183372],\n",
       "       [143.39983051],\n",
       "       [231.71849   ],\n",
       "       [179.59535891],\n",
       "       [187.56243947],\n",
       "       [ 67.05964986],\n",
       "       [192.84191843],\n",
       "       [179.08027657],\n",
       "       [235.94996771],\n",
       "       [121.08637751],\n",
       "       [ 85.93905304],\n",
       "       [102.65017083],\n",
       "       [140.31649517],\n",
       "       [101.66657695],\n",
       "       [119.96430852],\n",
       "       [ 82.16098489],\n",
       "       [234.31452819],\n",
       "       [244.33866794],\n",
       "       [263.53283451],\n",
       "       [274.30429222],\n",
       "       [180.91762932],\n",
       "       [204.45453023],\n",
       "       [254.03323937],\n",
       "       [119.28896357],\n",
       "       [267.19515892],\n",
       "       [105.08321149],\n",
       "       [119.46191516],\n",
       "       [142.50982281],\n",
       "       [ 58.807832  ],\n",
       "       [130.39077413],\n",
       "       [263.39520208],\n",
       "       [ 46.17469178],\n",
       "       [125.0187723 ],\n",
       "       [131.70093752],\n",
       "       [ 35.64540901],\n",
       "       [139.17365621],\n",
       "       [246.10401878],\n",
       "       [ 89.1724053 ],\n",
       "       [192.71804663],\n",
       "       [166.23315911],\n",
       "       [147.79589786],\n",
       "       [192.59895656],\n",
       "       [177.56167389],\n",
       "       [159.86178668],\n",
       "       [188.01701815],\n",
       "       [117.08311908],\n",
       "       [113.82928222],\n",
       "       [118.61959402],\n",
       "       [166.10750875],\n",
       "       [ 98.10269213],\n",
       "       [141.14817148],\n",
       "       [ 85.3149742 ],\n",
       "       [161.52470754],\n",
       "       [203.30162645],\n",
       "       [ 79.99128073],\n",
       "       [146.91709814],\n",
       "       [ 81.14161392],\n",
       "       [190.03643798],\n",
       "       [221.95408679],\n",
       "       [203.46909044],\n",
       "       [ 93.3565789 ],\n",
       "       [178.7878351 ],\n",
       "       [ 83.91466859],\n",
       "       [152.06713318],\n",
       "       [ 78.34168866],\n",
       "       [ 98.41490946],\n",
       "       [108.56162588],\n",
       "       [125.62703969],\n",
       "       [217.90029179],\n",
       "       [127.53783653],\n",
       "       [207.05767561],\n",
       "       [230.19888487],\n",
       "       [124.47980723],\n",
       "       [136.71526057],\n",
       "       [127.63090393],\n",
       "       [150.98569723],\n",
       "       [ 88.5925505 ],\n",
       "       [139.48869288],\n",
       "       [204.52461607],\n",
       "       [173.83508424],\n",
       "       [122.9253427 ],\n",
       "       [214.36441981],\n",
       "       [174.70438665],\n",
       "       [110.22556227],\n",
       "       [198.73936678],\n",
       "       [174.83541512],\n",
       "       [163.61697039],\n",
       "       [193.79942594],\n",
       "       [191.47045414],\n",
       "       [285.50533597],\n",
       "       [279.46979662],\n",
       "       [216.51365647],\n",
       "       [210.84831584],\n",
       "       [215.64107793],\n",
       "       [158.55625638],\n",
       "       [224.23468435],\n",
       "       [188.77485924],\n",
       "       [105.07471765],\n",
       "       [180.78872664],\n",
       "       [114.49716858],\n",
       "       [291.21345392],\n",
       "       [184.36382653],\n",
       "       [ 80.18176355],\n",
       "       [ 86.91136289],\n",
       "       [248.78148064],\n",
       "       [176.34545208],\n",
       "       [122.15126229],\n",
       "       [146.07273095],\n",
       "       [171.50388525],\n",
       "       [184.66501163],\n",
       "       [165.42948001],\n",
       "       [157.82604851],\n",
       "       [143.70436507],\n",
       "       [127.03589361],\n",
       "       [177.62938237],\n",
       "       [105.52013381],\n",
       "       [132.73458358],\n",
       "       [ 97.5268931 ],\n",
       "       [250.1859579 ],\n",
       "       [ 86.81475817],\n",
       "       [ 62.41613529],\n",
       "       [154.45925987],\n",
       "       [191.6875602 ],\n",
       "       [134.74421673],\n",
       "       [ 94.28531437],\n",
       "       [201.15935714],\n",
       "       [ 53.73729167],\n",
       "       [176.76832337],\n",
       "       [197.79656254],\n",
       "       [119.63803358],\n",
       "       [236.11561006],\n",
       "       [166.17655703],\n",
       "       [162.37080447],\n",
       "       [164.02067674],\n",
       "       [252.92926842],\n",
       "       [256.45853973],\n",
       "       [197.70698794],\n",
       "       [184.82159384],\n",
       "       [ 59.2095776 ],\n",
       "       [193.66927062],\n",
       "       [111.23508373],\n",
       "       [142.60785153],\n",
       "       [127.65299855],\n",
       "       [181.28398173],\n",
       "       [210.83575857],\n",
       "       [170.72039696],\n",
       "       [165.17584707],\n",
       "       [137.74480707],\n",
       "       [175.68382577],\n",
       "       [ 75.3511821 ],\n",
       "       [245.44316502],\n",
       "       [115.3294497 ],\n",
       "       [111.81300072],\n",
       "       [141.55921954],\n",
       "       [111.02445384],\n",
       "       [ 91.9564145 ],\n",
       "       [164.19818587],\n",
       "       [ 74.89356839],\n",
       "       [253.68019464],\n",
       "       [ 54.68468661],\n",
       "       [100.04367036],\n",
       "       [100.83016925],\n",
       "       [257.81296474],\n",
       "       [169.57401414],\n",
       "       [ 62.70775773],\n",
       "       [183.11027608],\n",
       "       [170.34970265],\n",
       "       [190.15105413],\n",
       "       [187.19845707],\n",
       "       [ 88.17178554],\n",
       "       [151.59620981],\n",
       "       [250.30795981],\n",
       "       [199.91994535],\n",
       "       [284.01273725],\n",
       "       [ 50.53096422],\n",
       "       [173.03012803],\n",
       "       [205.73902656],\n",
       "       [174.78336203],\n",
       "       [157.74242737],\n",
       "       [150.48016954],\n",
       "       [234.26382757],\n",
       "       [121.60133488],\n",
       "       [165.79514728],\n",
       "       [173.46162171],\n",
       "       [227.5018786 ],\n",
       "       [149.09669413],\n",
       "       [ 99.5856398 ],\n",
       "       [ 81.87865626],\n",
       "       [142.75810005],\n",
       "       [193.01616829]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print your `diabetes_target_test` and compare with the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212.]\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "print(diabetes_target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is `diabetes_target_test` exactly the same as the model prediction? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   233.0\n",
       "1    91.0\n",
       "2   111.0\n",
       "3   152.0\n",
       "4   120.0\n",
       "5    67.0\n",
       "6   310.0\n",
       "7    94.0\n",
       "8   183.0\n",
       "9    66.0\n",
       "10  173.0\n",
       "11   72.0\n",
       "12   49.0\n",
       "13   64.0\n",
       "14   48.0\n",
       "15  178.0\n",
       "16  104.0\n",
       "17  132.0\n",
       "18  220.0\n",
       "19   57.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [20, 422]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-850dd09cab91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Your explanation here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiabetes_target_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiabetes_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [20, 422]"
     ]
    }
   ],
   "source": [
    "# Your explanation here:\n",
    "accuracy_score(diabetes_target_test, diabetes_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 1 - Hypothesis Testing with `statsmodels`\n",
    "\n",
    "After generating the linear regression model from the dataset, you probably wonder: then what? What is the statistical way to know if my model is reliable or not?\n",
    "\n",
    "Good question. We'll discuss that using Scikit-Learn in Challenge 5. But for now, let's use a fool-proof way by using the ([Linear Regression class of StatsModels](https://www.statsmodels.org/dev/regression.html)) which can also conduct linear regression analysis plus much more such as calcuating the F-score of the linear model as well as the standard errors and t-scores for each coefficient. The F-score and t-scores will tell you whether you can trust your linear model.\n",
    "\n",
    "To understand the statistical meaning of conducting hypothesis testing (e.g. F-test, t-test) for slopes, read [this webpage](https://onlinecourses.science.psu.edu/stat501/node/297/) at your leisure time. We'll give you a brief overview next.\n",
    "\n",
    "* The F-test of your linear model is to verify whether at least one of your coefficients is significantly different from zero. Translating that into the *null hypothesis* and *alternative hypothesis*, that is:\n",
    "\n",
    "    ```\n",
    "    H0 : β1 = β2 = ... = β10 = 0\n",
    "    HA : At least one βj ≠ 0 (for j = 1, 2, ..., 10)\n",
    "    ```\n",
    "\n",
    "* The t-tests on each coefficient is to check whether the confidence interval for the variable contains zero. If the confidence interval contains zero, it means the null hypothesis for that variable is not rejected. In other words, this particular vaiable is not contributing to your linear model and you can remove it from your formula.\n",
    "\n",
    "Read the documentations of [StatsModels Linear Regression](https://www.statsmodels.org/dev/regression.html) as well as its [`OLS` class](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html) which stands for *ordinary least squares*.\n",
    "\n",
    "#### In the next cell, analyze `diabetes_data_train` and `diabetes_target_train` with the linear regression model of `statsmodels`. Print the fit summary.\n",
    "\n",
    "Your output should look like:\n",
    "\n",
    "![statsmodels regression](../statsmodels.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.071397</td>\n",
       "      <td>-0.074528</td>\n",
       "      <td>-0.015328</td>\n",
       "      <td>-0.001314</td>\n",
       "      <td>0.004460</td>\n",
       "      <td>-0.021412</td>\n",
       "      <td>-0.046879</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.009016</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.024529</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>0.098876</td>\n",
       "      <td>0.094196</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.021394</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>-0.020045</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.054707</td>\n",
       "      <td>-0.053871</td>\n",
       "      <td>-0.066239</td>\n",
       "      <td>-0.057367</td>\n",
       "      <td>0.011824</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.074089</td>\n",
       "      <td>-0.005220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.023546</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.034698</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>0.061054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.039710</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>0.071210</td>\n",
       "      <td>0.049769</td>\n",
       "      <td>0.015491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "417 -0.052738 -0.044642  0.071397 -0.074528 -0.015328 -0.001314  0.004460   \n",
       "418  0.009016 -0.044642 -0.024529 -0.026328  0.098876  0.094196  0.070730   \n",
       "419 -0.020045 -0.044642 -0.054707 -0.053871 -0.066239 -0.057367  0.011824   \n",
       "420  0.023546 -0.044642 -0.036385  0.000068  0.001183  0.034698 -0.043401   \n",
       "421  0.038076  0.050680  0.016428  0.021872  0.039710  0.045032 -0.043401   \n",
       "\n",
       "            7         8         9  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "417 -0.021412 -0.046879  0.003064  \n",
       "418 -0.002592 -0.021394  0.007207  \n",
       "419 -0.039493 -0.074089 -0.005220  \n",
       "420  0.034309 -0.033249  0.061054  \n",
       "421  0.071210  0.049769  0.015491  \n",
       "\n",
       "[422 rows x 10 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.OLS(diabetes_data_train, diabetes_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000026  0.000004  0.000075  0.000056  0.000024  0.000019 -0.000051   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.000055  0.000071  0.000046  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diabetes_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (422,10) and (422,10) not aligned: 10 (dim 1) != 422 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-6ce2ff78cdb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, yname, xname, title, alpha)\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0mrsquared_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m' (uncentered)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m         top_right = [('R-squared' + rsquared_type + ':',\n\u001b[0;32m-> 2640\u001b[0;31m                       [\"%#8.3f\" % self.rsquared]),\n\u001b[0m\u001b[1;32m   2641\u001b[0m                      ('Adj. R-squared' + rsquared_type + ':',\n\u001b[1;32m   2642\u001b[0m                       [\"%#8.3f\" % self.rsquared_adj]),\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mrsquared\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1715\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentered_tss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncentered_tss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mssr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;34m\"\"\"Sum of squared (whitened) residuals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m         \u001b[0mwresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwresid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwresid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (422,10) and (422,10) not aligned: 10 (dim 1) != 422 (dim 0)"
     ]
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting hypothesis testing results\n",
    "\n",
    "Answer the following questions in the cell below:\n",
    "\n",
    "1. What is the F-score of your linear model and is the null hypothesis rejected?\n",
    "\n",
    "1. Does any of the t-tests of the coefficients produce a confidence interval containing zero? What are they?\n",
    "\n",
    "1. How will you modify your linear reguression model according to the test results above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answers here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Peform Supervised Learning on a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have dealt with data that has been formatted for scikit-learn, let's look at data that we will need to format ourselves.\n",
    "\n",
    "In the next cell, load the `auto-mpg.csv` file included in this folder and assign it to a variable called `auto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "auto = pd.read_csv('auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 5 rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year                       car_name  \n",
       "0          70  \\t\"chevrolet chevelle malibu\"  \n",
       "1          70          \\t\"buick skylark 320\"  \n",
       "2          70         \\t\"plymouth satellite\"  \n",
       "3          70              \\t\"amc rebel sst\"  \n",
       "4          70                \\t\"ford torino\"  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the data to ensure that all numeric columns are correctly detected as such by pandas. If a column is misclassified as object, coerce it to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             float64\n",
       "cylinders         int64\n",
       "displacement    float64\n",
       "horse_power     float64\n",
       "weight            int64\n",
       "acceleration    float64\n",
       "model_year        int64\n",
       "car_name         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the newest model year and the oldest model year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto['model_year'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto['model_year'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset for missing values and remove all rows containing at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg             0\n",
       "cylinders       0\n",
       "displacement    0\n",
       "horse_power     6\n",
       "weight          0\n",
       "acceleration    0\n",
       "model_year      0\n",
       "car_name        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "missing_values = auto.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency table for the `cylinders` column using the `value_counts()` function. How many possible values of cylinders are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    199\n",
       "8    103\n",
       "6     83\n",
       "3      4\n",
       "5      3\n",
       "Name: cylinders, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto['cylinders'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate a linear regression model that will predict mpg. To do this, first drop the `car_name` column since it does not contain any quantitative data. Next separate the dataframe to predictor and response variables. Separate those into test and training data with 80% of the data in the training set and the remainder in the test set. \n",
    "\n",
    "Assign the predictor and response training data to `X_train` and `y_train` respectively. Similarly, assign the predictor and response test data to `X_test` and `y_test`.\n",
    "\n",
    "*Hint: To separate data for training and test, use the `train_test_split` method we used in previous labs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.drop(['car_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year  \n",
       "0          70  \n",
       "1          70  \n",
       "2          70  \n",
       "3          70  \n",
       "4          70  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_x = auto.drop(['mpg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_y = auto['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(auto_x, auto_y,random_state = 0, test_size = 0.20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will processed and peform linear regression on this data to predict the mpg for each vehicle. \n",
    "\n",
    "#### In the next cell, create an instance of the linear regression model and call it `auto_model`. Fit `auto_model` with your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "auto_model = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8088490656511089"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Evaluate the Model\n",
    "\n",
    "In addition to evaluating your model with F-test and t-test, you can also use the *Coefficient of Determination* (a.k.a. *r squared score*). This method does not simply tell *yes* or *no* about the model fit but instead indicates how much variation can be explained by the model. Based on the r squared score, you can decide whether to improve your model in order to obtain a better fit.\n",
    "\n",
    "You can learn about the r squared score [here](https://en.wikipedia.org/wiki/Coefficient_of_determination). In the end, we want the r-squared score to be as high as possible.\n",
    "\n",
    "#### In the next cell, compute the predicted *y* based on `X_train` and call it `y_pred`. Then calcualte the r squared score between `y_pred` and `y_train` which indicates how well the estimated regression model fits the training data.\n",
    "\n",
    "*Hint: r squared score can be calculated using `sklearn.metrics.r2_score` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "y_pred = auto_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636753969728356"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next step is to evaluate the model using the test data. \n",
    "\n",
    "We would like to ensure that our model is not overfitting the data. This means that our model was made to fit too closely to the training data by being overly complex. If a model is overfitted, it is not generalizable to data outside the training data. In that case, we need to reduce the complexity of the model by removing certain features (variables).\n",
    "\n",
    "In the cell below, use the model to generate the predicted values for the test data and assign them to `y_test_pred`. Compute the r squared score of the predicted `y_test_pred` and the oberserved `y_test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test_pred code here:\n",
    "y_test_pred = auto_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734388229664284"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explaining the results\n",
    "\n",
    "The r squared scores of the training data and the test data are pretty close (0.8146 vs 0.7818). This means our model is not overfitted. However, there is still room to improve the model fit. Move on to the next challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 5 - Improve the Model Fit\n",
    "\n",
    "While the most common way to improve the fit of a model is by using [regularization](https://datanice.github.io/machine-learning-101-what-is-regularization-interactive.html), there are other simpler ways to improve model fit. The first is to create a simpler model. The second is to increase the train sample size.\n",
    "\n",
    "Let us start with the easier option and increase our train sample size to 90% of the data. Create a new test train split and name the new predictors and response variables `X_train09`, `X_test09`, `y_train09`, `y_test09`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "X_train09, X_test09, y_train09, y_test09 = train_test_split(auto_x, auto_y,random_state = 0, test_size = 0.10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new linear regression model. Name this model `auto_model09`. Fit the model to the new sample (training) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "auto_model09 = linear_model.LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model09 = LinearRegression().fit(X_train09, y_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predicted values and r squared score for our new model and new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "y_test_pred09 = auto_model.predict(X_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the r squared score for the smaller test set. Is there an improvement in the test r squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7664077031269418"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "r2_score(y_test_pred09, y_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Backward Elimination \n",
    "\n",
    "The main way to produce a simpler linear regression model is to reduce the number of variables used in the model. In scikit-learn, we can do this by using recursive feature elimination. You can read more about RFE [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
    "\n",
    "In the next cell, we will import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the documentation and initialize an RFE model using the `auto_model` linear regression model. Set `n_features_to_select=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and print the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance is ranked from most important (1) to least important (4). Generate a model with the three most important features. The features correspond to variable names. For example, feature 1 is `cylinders` and feature 2 is `displacement`.\n",
    "\n",
    "Perform a test-train split on this reduced column data and call the split data `X_train_reduced`, `X_test_reduced`, `y_test_reduced`, `y_train_reduced`. Use an 80% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new model called `auto_model_reduced` and fit this model. Then proceed to compute the r squared score for the model. Did this cause an improvement in the r squared score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "You may obtain the impression from this lab that without knowing statistical methods in depth, it is difficult to make major progress in machine learning. That is correct. If you are motivated to become a data scientist, statistics is the subject you must be proficient in and there is no shortcut. \n",
    "\n",
    "Completing these labs is not likely to make you a data scientist. But you will have a good sense about what are there in machine learning and what are good for you. In your future career, you can choose one of the three tracks:\n",
    "\n",
    "* Data scientists who need to be proficient in statistical methods.\n",
    "\n",
    "* Data engineers who need to be good at programming.\n",
    "\n",
    "* Data integration specialists who are business or content experts but also understand data and programming. This cross-disciplinary track brings together data, technology, and business and will be in high demands in the next decade."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
